{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "**Probelm Statement:** Make a classifier which takes in a job description and gives the department name for it.\n",
    "*   Use a neural network model\n",
    "*   Make use of a pre-trained Word Embeddings (example: Word2Vec, GloVe, etc.)\n",
    "*   Calculate the accuracy on a test set (data not used to train the model)\n",
    "\n",
    "**Problem Solving Approach:** \n",
    "_Provide a brief description of steps you followed for solving this problem_\n",
    "1. Understanding the data and different classes to classify jobs into\n",
    "2. Will try to take 75% jobs of each department to train and rest 25% to test\n",
    "3. Output class will be a one hot vector \n",
    "4. Input will be observed attributes of a job description. Will use word2vec or universal sentence encoder to compute embedding of a sentence to feed as an attribute of a job description.\n",
    "5. Starting with a simple 2 layer neural network to see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Text Preprocessing\n",
    "\n",
    "_Include all text preprocesing steps like processing of json,csv files & data cleaning in this part._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import neccessary packages in below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'company_info', u'api_data', u'other_details', u'topbox_information', u'jd_information', u'_id']\n",
      "cmts is engaged in the data entry outsourcing and supply of skilled/semi skilled &amp; unskilled Manpower across the industry spectrum. Our pool of manpower ranges from professionals such as Sales &amp; technical professionals in different categories, IT professionals, aviation sector, technical profiles, engineers, non-technical in-house professionals, administrative profiles, Accountant, HR, Back office, Data Entry Operator etc. Our organization's goal is total clients satisfaction through quality and personalized delivery of each and every service. We therefore exist to cater the need of these prospecting employers/companies since our inception in 2008.\n",
      "company_info\n",
      "api_data\n",
      "other_details\n",
      "topbox_information\n",
      "jd_information\n",
      "_id\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('data/document_departments.csv') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "\n",
    "description = {}\n",
    "for i in xrange(1,len(content)):\n",
    "    k = content[i].split(',')[1][:-2].strip()\n",
    "    if k in description.keys():\n",
    "        description[k].append(content[i].split(',')[0])\n",
    "    else:\n",
    "        description[k] = []\n",
    "        description[k].append(content[i].split(',')[0])\n",
    "        \n",
    "with open('data/docs/5922081.json', 'r') as myfile:\n",
    "    data=str(myfile.read())\n",
    "\n",
    "# parse file\n",
    "obj = json.loads(data)\n",
    "print(obj.keys())\n",
    "print(obj['company_info']['Company Description'])\n",
    "for k in obj.keys():\n",
    "    print(k)\n",
    "    if type(obj[k]) == 'dict':\n",
    "        print(obj[k].keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "word_model = gensim.models.KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/anshul/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "#Resusable functions keeping the problem and preprocessing of text in mind\n",
    "\n",
    "def preprocess(sen):\n",
    "    if sen == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    if type(sen) is list:\n",
    "        s = \"\"\n",
    "        for word in sen:\n",
    "            s += word + ' '\n",
    "        sen = s[:-1]\n",
    "    sen = sen.replace(\"&nbsp;\", ' ')\n",
    "    sen = sen.replace(\"&amp;\", ' ')\n",
    "    sen = sen.replace('.', ' ')\n",
    "    sen = sen.replace(',', ' ')\n",
    "    sen = sen.lower()\n",
    "    sen = re.sub(r'\\d+', '', sen)\n",
    "    \n",
    "    #sen = sen.translate(string.maketrans('','', string.punctuation))\n",
    "    exclude = set(string.punctuation)\n",
    "    for c in exclude:\n",
    "        sen = sen.replace(c, ' ')\n",
    "    sen = ''.join(ch for ch in sen if ch not in exclude)\n",
    "    sen = sen.strip()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(sen)\n",
    "    sen = [i for i in tokens if not i in stop_words]\n",
    "    return sen\n",
    "\n",
    "def embed(sen):\n",
    "    \n",
    "    sen = preprocess(sen)\n",
    "    #print(sen)\n",
    "    emm = np.ones(300)/100\n",
    "    em = np.zeros(300)\n",
    "    count = 0\n",
    "    words_not_found = 0\n",
    "    for w in sen:\n",
    "        try:\n",
    "            em += word_model[w]\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            #print(w, \"Not found\")\n",
    "            words_not_found += 1\n",
    "            continue\n",
    "    \n",
    "    #print(em/count)\n",
    "    if sen == \"\" or count == 0:\n",
    "        return emm\n",
    "    return em/count\n",
    "\n",
    "def get_training_data(obj):\n",
    "    #print obj['jd_information']['description']\n",
    "    data = []\n",
    "    try:\n",
    "        data.append(embed(obj['company_info']['Company Description']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['company_info']['Company Name']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['api_data']['job_keywords']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['api_data']['job_industry']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['api_data']['job_title']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['other_details']['Other Skills:']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['other_details']['Industry:']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['other_details']['Department:']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    try:\n",
    "        data.append(embed(obj['jd_information']['description']))\n",
    "    except KeyError:\n",
    "        data.append(embed(\"\"))\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Constructing data for out model\n",
    "\n",
    "import numpy as np\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "# l_train = []\n",
    "# l_test = []\n",
    "key_count = 0\n",
    "\n",
    "for k in description.keys():\n",
    "    output = np.zeros(len(description.keys()))\n",
    "    output[key_count] = 1\n",
    "    label = key_count\n",
    "    key_count = key_count + 1\n",
    "    for i in range(len(description[k])):\n",
    "        with open('data/docs/' + description[k][i] + '.json', 'r') as myfile:\n",
    "            data=str(myfile.read())\n",
    "        obj = json.loads(data)\n",
    "        inp = get_training_data(obj)\n",
    "#         print(inp)\n",
    "#         break\n",
    "#     break\n",
    "        #70% for training\n",
    "        if i < 0.7 * len(description[k]):\n",
    "            \n",
    "            x_train.append(inp)\n",
    "            y_train.append(output)\n",
    "#             l_train.append(label)\n",
    "        #30% for testing\n",
    "        else:\n",
    "            x_test.append(inp)\n",
    "            y_test.append(output)\n",
    "#             l_test.append(label)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(827,\n",
       " 335,\n",
       " 9,\n",
       " 300,\n",
       " [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([ 0.15043945, -0.11409912, -0.16625977, -0.03572388, -0.02372742,\n",
       "          0.08888245,  0.04412231, -0.11555176,  0.11821899, -0.09246216,\n",
       "         -0.0170311 , -0.05019836, -0.17026367,  0.02425385,  0.00804443,\n",
       "          0.01019897,  0.14376221,  0.08432007,  0.02273254, -0.01026001,\n",
       "          0.0309082 ,  0.06522217,  0.12804413,  0.07874756, -0.04986572,\n",
       "         -0.01968384, -0.00511475,  0.16234131,  0.06293945, -0.10771332,\n",
       "         -0.10283813,  0.02043457, -0.12556763,  0.03206787,  0.10875854,\n",
       "         -0.03791504, -0.00741196,  0.04932861,  0.26708984, -0.03401794,\n",
       "          0.01397552, -0.0660141 , -0.00877609,  0.12088623, -0.077948  ,\n",
       "         -0.16368103,  0.00789185,  0.06864319, -0.02525635,  0.06679688,\n",
       "          0.03513031,  0.04550781, -0.01802673,  0.02879868, -0.00597229,\n",
       "          0.07020874,  0.00184937, -0.05647964,  0.07963257, -0.02245331,\n",
       "         -0.07564087, -0.10651245, -0.14667969,  0.05529633, -0.22008209,\n",
       "         -0.03444977, -0.09214268,  0.04072266,  0.14985275,  0.0838974 ,\n",
       "         -0.08374634,  0.12049255,  0.07676697,  0.09519653,  0.03476868,\n",
       "         -0.0067627 ,  0.06473389,  0.10344238, -0.01199341, -0.02648315,\n",
       "          0.00199051,  0.02938538,  0.06387329,  0.09907227,  0.05910645,\n",
       "         -0.11025543, -0.05020905,  0.07380371,  0.01037903,  0.15840149,\n",
       "          0.05562744, -0.21965942, -0.16014252, -0.13395386,  0.04433746,\n",
       "         -0.04340363,  0.05391769, -0.05666504,  0.19391022,  0.26462402,\n",
       "          0.03201294, -0.02006024,  0.0110321 ,  0.0684845 ,  0.04463501,\n",
       "         -0.00655518, -0.13838501,  0.02036743,  0.06412201, -0.16584473,\n",
       "         -0.16437225,  0.04061584, -0.15772705, -0.0015625 ,  0.20698242,\n",
       "          0.00321808, -0.08560867, -0.10510864,  0.21300049,  0.01920166,\n",
       "         -0.0380722 ,  0.00957642, -0.18724232,  0.17444458,  0.06519775,\n",
       "          0.05041504, -0.07597046,  0.17075195,  0.04676819,  0.01939087,\n",
       "         -0.14424438,  0.03477173, -0.18942871,  0.02037659, -0.14415894,\n",
       "          0.11003418,  0.06776123,  0.07589569,  0.05742035, -0.06345215,\n",
       "          0.14551392, -0.1864502 , -0.03728027, -0.06398926,  0.07932129,\n",
       "         -0.08633118,  0.15701904, -0.07017517, -0.15889816, -0.1618042 ,\n",
       "          0.08015137,  0.14438477, -0.03031006, -0.03362122,  0.03711548,\n",
       "         -0.09969482,  0.01758118, -0.05958862,  0.00379639,  0.04757996,\n",
       "         -0.24216309,  0.02032471, -0.17464905,  0.12687988,  0.09190063,\n",
       "         -0.01305542, -0.02089996, -0.21506958, -0.1079071 , -0.00264282,\n",
       "          0.04995422, -0.06485901,  0.12545166, -0.0956665 , -0.0036499 ,\n",
       "          0.05023956,  0.16107178, -0.11630554, -0.05783691, -0.07023926,\n",
       "          0.07855721, -0.15610352, -0.07850342, -0.10136108,  0.12519836,\n",
       "         -0.13693848, -0.1263092 ,  0.10707092,  0.11276245,  0.02242737,\n",
       "         -0.03168335, -0.00265808, -0.07913589, -0.01208496, -0.05453453,\n",
       "          0.05782776,  0.05410461, -0.07208252,  0.04024353, -0.21617737,\n",
       "         -0.04356689,  0.08686523,  0.11497192,  0.03353424,  0.03131256,\n",
       "         -0.03482323,  0.08849487, -0.13345337, -0.10000305,  0.15441284,\n",
       "         -0.00582581,  0.04575195, -0.16537323, -0.037117  ,  0.10796356,\n",
       "          0.07432251,  0.08808594, -0.02854919, -0.14837646, -0.0260498 ,\n",
       "         -0.07117004,  0.00559082,  0.1225647 , -0.06536865, -0.03868713,\n",
       "         -0.064151  , -0.00767212, -0.14212036, -0.02658081, -0.13404846,\n",
       "         -0.09709778, -0.09356689, -0.06696167, -0.05899353,  0.02403564,\n",
       "         -0.06011353,  0.12420044,  0.00142307,  0.08515625,  0.12233887,\n",
       "          0.07367783, -0.03151855, -0.02320251, -0.12580566,  0.04621277,\n",
       "         -0.06654968, -0.08766174,  0.23581543, -0.09352112, -0.12005615,\n",
       "          0.04642334, -0.00239868, -0.01514282,  0.08149872,  0.05543213,\n",
       "         -0.04747314, -0.09093628,  0.0208786 , -0.0831665 , -0.21801758,\n",
       "          0.07158508, -0.03383789,  0.15153809, -0.00064621, -0.0795105 ,\n",
       "          0.04066162, -0.15808105, -0.12184143, -0.18399048, -0.11761169,\n",
       "          0.01120605,  0.14160862, -0.0221283 , -0.08420715,  0.03549957,\n",
       "          0.00198975, -0.06401978,  0.0871582 ,  0.18337402,  0.06312256,\n",
       "         -0.1388916 , -0.00509033,  0.06167908,  0.02409096, -0.09083862,\n",
       "          0.10259628, -0.12758789,  0.22878418,  0.21836548,  0.01063843,\n",
       "          0.06614685,  0.06488037, -0.14887085,  0.04571991,  0.08281403,\n",
       "         -0.16148682,  0.22052612, -0.05231628, -0.00793304,  0.01225586]),\n",
       "  array([ 0.1796875 , -0.00341797, -0.12304688, -0.04638672, -0.00708008,\n",
       "          0.06677246, -0.21582031, -0.34375   ,  0.02624512, -0.16210938,\n",
       "          0.17382812, -0.02526855, -0.15576172,  0.05474854,  0.03717041,\n",
       "         -0.03564453, -0.05322266,  0.28027344,  0.1315918 , -0.0057373 ,\n",
       "         -0.08935547,  0.02148438,  0.0078125 ,  0.06286621, -0.10461426,\n",
       "          0.05224609,  0.19921875, -0.01843262,  0.32714844, -0.04394531,\n",
       "         -0.08526611, -0.13916016, -0.20947266,  0.08331299,  0.06164551,\n",
       "         -0.24316406,  0.07617188,  0.19091797,  0.09570312, -0.02978516,\n",
       "         -0.08319092, -0.14111328,  0.13867188,  0.15136719, -0.03619385,\n",
       "         -0.4296875 ,  0.16381836, -0.0435791 , -0.00830078,  0.15234375,\n",
       "          0.05310059,  0.07971191, -0.06640625,  0.11352539, -0.11547852,\n",
       "         -0.12280273, -0.14746094,  0.1550293 ,  0.10693359,  0.17431641,\n",
       "         -0.16821289, -0.13134766, -0.09643555, -0.08227539, -0.06494141,\n",
       "         -0.0244751 , -0.30859375,  0.02832031,  0.22094727, -0.01171875,\n",
       "         -0.30310059,  0.01337814,  0.24316406, -0.0736084 , -0.14892578,\n",
       "         -0.08642578, -0.25048828,  0.14477539, -0.10107422,  0.0012207 ,\n",
       "         -0.13549805, -0.19714355, -0.20068359,  0.06835938, -0.12036133,\n",
       "          0.13391113, -0.40722656,  0.03369141, -0.05749512,  0.22265625,\n",
       "          0.296875  , -0.19970703, -0.06970215, -0.3203125 ,  0.04418945,\n",
       "          0.027771  ,  0.25097656, -0.01123047,  0.26635742, -0.11865234,\n",
       "         -0.10317993,  0.0925293 ,  0.20361328,  0.12866211,  0.24951172,\n",
       "          0.03173828,  0.06500244, -0.14111328,  0.20703125, -0.30761719,\n",
       "         -0.13037109, -0.02001953,  0.25219727, -0.00256348,  0.02734375,\n",
       "         -0.02154541,  0.13916016, -0.15563965,  0.08959961, -0.01699829,\n",
       "         -0.19433594,  0.21240234,  0.02282715,  0.24658203, -0.00878906,\n",
       "          0.12121582, -0.03149414, -0.12304688, -0.12451172,  0.05932617,\n",
       "         -0.17407227,  0.05859375,  0.09643555, -0.19287109, -0.18212891,\n",
       "         -0.10906982, -0.21484375,  0.19628906, -0.06750488,  0.01208496,\n",
       "          0.0604248 , -0.23242188,  0.00699615, -0.02496338, -0.00097656,\n",
       "         -0.19189453, -0.07324219,  0.07617188, -0.04418945,  0.1015625 ,\n",
       "          0.10424805, -0.07495117, -0.02563477, -0.14819336,  0.09277344,\n",
       "         -0.09197998,  0.21630859, -0.26806641,  0.09594727, -0.09448242,\n",
       "         -0.08862305, -0.10046387,  0.05801773,  0.13366699,  0.05957031,\n",
       "          0.14013672, -0.04858398, -0.34765625, -0.02923584, -0.07159424,\n",
       "          0.04248047,  0.11948395,  0.12744141, -0.09362793, -0.08306885,\n",
       "          0.19091797,  0.21134949, -0.09475708, -0.08538818,  0.05474854,\n",
       "         -0.14416504, -0.19140625, -0.18261719, -0.18505859, -0.03381348,\n",
       "         -0.1262207 ,  0.13818359, -0.10308838,  0.12207031,  0.10894775,\n",
       "          0.20855713,  0.15234375,  0.17529297,  0.32568359, -0.04437256,\n",
       "          0.15649414,  0.04205322, -0.10388184, -0.03466797, -0.29101562,\n",
       "          0.13964844, -0.01544189,  0.01669312, -0.13513184, -0.18701172,\n",
       "         -0.0859375 ,  0.18701172, -0.08337402,  0.12078857,  0.08447266,\n",
       "          0.03855896,  0.07629395, -0.07250977,  0.24121094, -0.03930664,\n",
       "          0.33398438,  0.27880859,  0.18652344,  0.08813477,  0.00439453,\n",
       "          0.26269531, -0.26904297,  0.12866211,  0.06573486, -0.00708008,\n",
       "         -0.11645508,  0.13018799, -0.02947998, -0.04696655,  0.14038086,\n",
       "          0.00634766, -0.08618164, -0.15869141, -0.03216553, -0.16296387,\n",
       "          0.0390625 ,  0.03076172, -0.06809998,  0.06054688, -0.14746094,\n",
       "          0.01489258,  0.05667114,  0.09741211, -0.12963867,  0.03820801,\n",
       "         -0.07275391, -0.01025391, -0.29589844, -0.01647949,  0.00463867,\n",
       "          0.0078125 ,  0.05645752,  0.04541016,  0.07885742,  0.12011719,\n",
       "         -0.00195312,  0.22680664,  0.01391602, -0.08996582, -0.18488312,\n",
       "         -0.00244141,  0.10742188,  0.12670898,  0.23193359, -0.00488281,\n",
       "          0.1953125 ,  0.0489502 , -0.0234375 , -0.1184082 , -0.03198242,\n",
       "          0.15209961,  0.16357422, -0.05541992, -0.13246155,  0.03491211,\n",
       "         -0.35595703, -0.06964111, -0.12374878, -0.04272461, -0.01611328,\n",
       "         -0.05822754, -0.05004883,  0.17613602, -0.40332031,  0.11108398,\n",
       "          0.07388306, -0.34863281,  0.03710938, -0.12744141,  0.19873047,\n",
       "         -0.08032227, -0.11914062, -0.03448486, -0.01123047,  0.19482422,\n",
       "          0.09423828,  0.10217285, -0.11743164,  0.36621094, -0.01904297]),\n",
       "  array([-0.03011068, -0.09838867, -0.17675781, -0.09851074,  0.05729167,\n",
       "          0.04622396,  0.04077148, -0.05029297,  0.0065918 , -0.02986654,\n",
       "         -0.02994792, -0.04793294, -0.05965169, -0.05752563, -0.09594727,\n",
       "          0.15218099,  0.24479167, -0.01383464,  0.06624349,  0.08831787,\n",
       "          0.04003906, -0.01025391, -0.02897135,  0.01595052, -0.03564453,\n",
       "         -0.01413981, -0.03047689,  0.16276042, -0.11092122, -0.06119792,\n",
       "         -0.13684082,  0.02628581, -0.07714844,  0.02766927,  0.15580241,\n",
       "          0.03320312, -0.00374349,  0.07877604,  0.15917969, -0.01318359,\n",
       "         -0.05997721, -0.1319987 , -0.0049235 ,  0.06770833, -0.153361  ,\n",
       "         -0.28092448, -0.02115885,  0.13517253, -0.05639648,  0.08024089,\n",
       "          0.02229818,  0.04915365,  0.00769043,  0.14428711, -0.01083374,\n",
       "          0.00744629, -0.12215169, -0.11328125,  0.04231771, -0.04402669,\n",
       "         -0.09985352,  0.00130208, -0.10766602,  0.10241699, -0.20857747,\n",
       "          0.01742554, -0.05061849, -0.015625  ,  0.29427083,  0.10424805,\n",
       "         -0.03678385, -0.02897135,  0.04219055,  0.15266927,  0.07902018,\n",
       "         -0.04870605,  0.04134115,  0.06510417, -0.00612386,  0.00878906,\n",
       "          0.09847005, -0.04142253, -0.00874837,  0.10473633, -0.01953125,\n",
       "         -0.04251099, -0.07322184,  0.0069987 ,  0.04054769,  0.12841797,\n",
       "          0.05623372, -0.12076823, -0.13985189, -0.1936849 ,  0.02018738,\n",
       "         -0.00558472,  0.04817708, -0.02587891,  0.06702169,  0.12939453,\n",
       "          0.1077474 ,  0.09399414, -0.04443359,  0.05627441,  0.09863281,\n",
       "         -0.09790039, -0.12866211, -0.07686361,  0.06469727, -0.09488932,\n",
       "         -0.08487956,  0.00956217, -0.11848958, -0.09545898,  0.0694987 ,\n",
       "         -0.04313151,  0.03542074,  0.02998861,  0.33919271,  0.05423991,\n",
       "         -0.03260295,  0.00341797, -0.12858073,  0.15266927,  0.01472982,\n",
       "         -0.01969401, -0.0304362 ,  0.14404297,  0.14469401,  0.08821615,\n",
       "         -0.04414876, -0.10925293, -0.16634115,  0.04272461, -0.14400228,\n",
       "          0.11499023, -0.03157552,  0.0559082 , -0.01181539,  0.03922526,\n",
       "          0.05957031, -0.16259766, -0.04541016, -0.06429036, -0.06494141,\n",
       "         -0.06447347,  0.13671875, -0.06849416, -0.00130208, -0.02657064,\n",
       "         -0.00146484,  0.23177083,  0.00970459,  0.04980469,  0.16296387,\n",
       "         -0.1110026 ,  0.04054769, -0.01849365,  0.04736328,  0.02994792,\n",
       "         -0.14713542, -0.19832357, -0.11539714,  0.16666667,  0.06903076,\n",
       "         -0.06445312, -0.03035482, -0.15039062, -0.01513672,  0.11499023,\n",
       "          0.03389486, -0.19425456,  0.08312988, -0.11319987, -0.02441406,\n",
       "         -0.05452474,  0.00797526, -0.07347616,  0.07486979,  0.00565592,\n",
       "         -0.05814997, -0.12809245,  0.07674154, -0.22526042,  0.08789062,\n",
       "         -0.13293457, -0.13948568,  0.08140055,  0.0806071 ,  0.10270182,\n",
       "         -0.08699544, -0.03873698, -0.06148275,  0.04121908, -0.04335531,\n",
       "         -0.04410807,  0.02612305, -0.02669271,  0.00089518, -0.125     ,\n",
       "         -0.03580729,  0.0308431 ,  0.12573242,  0.02346802,  0.05069987,\n",
       "         -0.04618327,  0.02697754, -0.03474935, -0.12770589,  0.18538411,\n",
       "         -0.03377279,  0.01936849, -0.15193685,  0.14786784,  0.16168213,\n",
       "          0.15185547,  0.16886393, -0.04654948, -0.01293945, -0.09041341,\n",
       "          0.0476888 , -0.07694499,  0.12361654, -0.01253255,  0.0929362 ,\n",
       "         -0.11767578,  0.04166667, -0.09798177,  0.08284505, -0.14949544,\n",
       "         -0.14099121, -0.13037109, -0.02213542,  0.0152181 ,  0.05615234,\n",
       "         -0.01757812,  0.08162435, -0.03027344,  0.03759766,  0.0855306 ,\n",
       "          0.00297038, -0.10164388, -0.09956868, -0.15836589, -0.02050781,\n",
       "         -0.03027344, -0.07714844,  0.05419922,  0.0485026 , -0.16699219,\n",
       "          0.01969401, -0.00398763, -0.08799235, -0.11372884,  0.03629557,\n",
       "          0.02441406, -0.12858073,  0.05086263, -0.03792318, -0.08626302,\n",
       "          0.05712891, -0.02018229,  0.13932292,  0.03955078, -0.12093099,\n",
       "         -0.01285807, -0.10042318,  0.01436361, -0.23404948, -0.0806071 ,\n",
       "          0.04248047,  0.11405436, -0.09952799,  0.02195231, -0.11408488,\n",
       "         -0.00724284, -0.07312012, -0.01790365,  0.08902995,  0.06694031,\n",
       "         -0.01171875, -0.07926432, -0.02075195,  0.07248179,  0.0115153 ,\n",
       "          0.22167969, -0.16943359,  0.08561198,  0.24772135, -0.08626302,\n",
       "         -0.02633667, -0.0427653 , -0.15983073,  0.00325521, -0.04340617,\n",
       "         -0.13818359,  0.17708333,  0.02832031,  0.08148193,  0.01806641]),\n",
       "  array([ 0.15043945, -0.11409912, -0.16625977, -0.03572388, -0.02372742,\n",
       "          0.08888245,  0.04412231, -0.11555176,  0.11821899, -0.09246216,\n",
       "         -0.0170311 , -0.05019836, -0.17026367,  0.02425385,  0.00804443,\n",
       "          0.01019897,  0.14376221,  0.08432007,  0.02273254, -0.01026001,\n",
       "          0.0309082 ,  0.06522217,  0.12804413,  0.07874756, -0.04986572,\n",
       "         -0.01968384, -0.00511475,  0.16234131,  0.06293945, -0.10771332,\n",
       "         -0.10283813,  0.02043457, -0.12556763,  0.03206787,  0.10875854,\n",
       "         -0.03791504, -0.00741196,  0.04932861,  0.26708984, -0.03401794,\n",
       "          0.01397552, -0.0660141 , -0.00877609,  0.12088623, -0.077948  ,\n",
       "         -0.16368103,  0.00789185,  0.06864319, -0.02525635,  0.06679688,\n",
       "          0.03513031,  0.04550781, -0.01802673,  0.02879868, -0.00597229,\n",
       "          0.07020874,  0.00184937, -0.05647964,  0.07963257, -0.02245331,\n",
       "         -0.07564087, -0.10651245, -0.14667969,  0.05529633, -0.22008209,\n",
       "         -0.03444977, -0.09214268,  0.04072266,  0.14985275,  0.0838974 ,\n",
       "         -0.08374634,  0.12049255,  0.07676697,  0.09519653,  0.03476868,\n",
       "         -0.0067627 ,  0.06473389,  0.10344238, -0.01199341, -0.02648315,\n",
       "          0.00199051,  0.02938538,  0.06387329,  0.09907227,  0.05910645,\n",
       "         -0.11025543, -0.05020905,  0.07380371,  0.01037903,  0.15840149,\n",
       "          0.05562744, -0.21965942, -0.16014252, -0.13395386,  0.04433746,\n",
       "         -0.04340363,  0.05391769, -0.05666504,  0.19391022,  0.26462402,\n",
       "          0.03201294, -0.02006024,  0.0110321 ,  0.0684845 ,  0.04463501,\n",
       "         -0.00655518, -0.13838501,  0.02036743,  0.06412201, -0.16584473,\n",
       "         -0.16437225,  0.04061584, -0.15772705, -0.0015625 ,  0.20698242,\n",
       "          0.00321808, -0.08560867, -0.10510864,  0.21300049,  0.01920166,\n",
       "         -0.0380722 ,  0.00957642, -0.18724232,  0.17444458,  0.06519775,\n",
       "          0.05041504, -0.07597046,  0.17075195,  0.04676819,  0.01939087,\n",
       "         -0.14424438,  0.03477173, -0.18942871,  0.02037659, -0.14415894,\n",
       "          0.11003418,  0.06776123,  0.07589569,  0.05742035, -0.06345215,\n",
       "          0.14551392, -0.1864502 , -0.03728027, -0.06398926,  0.07932129,\n",
       "         -0.08633118,  0.15701904, -0.07017517, -0.15889816, -0.1618042 ,\n",
       "          0.08015137,  0.14438477, -0.03031006, -0.03362122,  0.03711548,\n",
       "         -0.09969482,  0.01758118, -0.05958862,  0.00379639,  0.04757996,\n",
       "         -0.24216309,  0.02032471, -0.17464905,  0.12687988,  0.09190063,\n",
       "         -0.01305542, -0.02089996, -0.21506958, -0.1079071 , -0.00264282,\n",
       "          0.04995422, -0.06485901,  0.12545166, -0.0956665 , -0.0036499 ,\n",
       "          0.05023956,  0.16107178, -0.11630554, -0.05783691, -0.07023926,\n",
       "          0.07855721, -0.15610352, -0.07850342, -0.10136108,  0.12519836,\n",
       "         -0.13693848, -0.1263092 ,  0.10707092,  0.11276245,  0.02242737,\n",
       "         -0.03168335, -0.00265808, -0.07913589, -0.01208496, -0.05453453,\n",
       "          0.05782776,  0.05410461, -0.07208252,  0.04024353, -0.21617737,\n",
       "         -0.04356689,  0.08686523,  0.11497192,  0.03353424,  0.03131256,\n",
       "         -0.03482323,  0.08849487, -0.13345337, -0.10000305,  0.15441284,\n",
       "         -0.00582581,  0.04575195, -0.16537323, -0.037117  ,  0.10796356,\n",
       "          0.07432251,  0.08808594, -0.02854919, -0.14837646, -0.0260498 ,\n",
       "         -0.07117004,  0.00559082,  0.1225647 , -0.06536865, -0.03868713,\n",
       "         -0.064151  , -0.00767212, -0.14212036, -0.02658081, -0.13404846,\n",
       "         -0.09709778, -0.09356689, -0.06696167, -0.05899353,  0.02403564,\n",
       "         -0.06011353,  0.12420044,  0.00142307,  0.08515625,  0.12233887,\n",
       "          0.07367783, -0.03151855, -0.02320251, -0.12580566,  0.04621277,\n",
       "         -0.06654968, -0.08766174,  0.23581543, -0.09352112, -0.12005615,\n",
       "          0.04642334, -0.00239868, -0.01514282,  0.08149872,  0.05543213,\n",
       "         -0.04747314, -0.09093628,  0.0208786 , -0.0831665 , -0.21801758,\n",
       "          0.07158508, -0.03383789,  0.15153809, -0.00064621, -0.0795105 ,\n",
       "          0.04066162, -0.15808105, -0.12184143, -0.18399048, -0.11761169,\n",
       "          0.01120605,  0.14160862, -0.0221283 , -0.08420715,  0.03549957,\n",
       "          0.00198975, -0.06401978,  0.0871582 ,  0.18337402,  0.06312256,\n",
       "         -0.1388916 , -0.00509033,  0.06167908,  0.02409096, -0.09083862,\n",
       "          0.10259628, -0.12758789,  0.22878418,  0.21836548,  0.01063843,\n",
       "          0.06614685,  0.06488037, -0.14887085,  0.04571991,  0.08281403,\n",
       "         -0.16148682,  0.22052612, -0.05231628, -0.00793304,  0.01225586]),\n",
       "  array([ 0.1796875 , -0.00341797, -0.12304688, -0.04638672, -0.00708008,\n",
       "          0.06677246, -0.21582031, -0.34375   ,  0.02624512, -0.16210938,\n",
       "          0.17382812, -0.02526855, -0.15576172,  0.05474854,  0.03717041,\n",
       "         -0.03564453, -0.05322266,  0.28027344,  0.1315918 , -0.0057373 ,\n",
       "         -0.08935547,  0.02148438,  0.0078125 ,  0.06286621, -0.10461426,\n",
       "          0.05224609,  0.19921875, -0.01843262,  0.32714844, -0.04394531,\n",
       "         -0.08526611, -0.13916016, -0.20947266,  0.08331299,  0.06164551,\n",
       "         -0.24316406,  0.07617188,  0.19091797,  0.09570312, -0.02978516,\n",
       "         -0.08319092, -0.14111328,  0.13867188,  0.15136719, -0.03619385,\n",
       "         -0.4296875 ,  0.16381836, -0.0435791 , -0.00830078,  0.15234375,\n",
       "          0.05310059,  0.07971191, -0.06640625,  0.11352539, -0.11547852,\n",
       "         -0.12280273, -0.14746094,  0.1550293 ,  0.10693359,  0.17431641,\n",
       "         -0.16821289, -0.13134766, -0.09643555, -0.08227539, -0.06494141,\n",
       "         -0.0244751 , -0.30859375,  0.02832031,  0.22094727, -0.01171875,\n",
       "         -0.30310059,  0.01337814,  0.24316406, -0.0736084 , -0.14892578,\n",
       "         -0.08642578, -0.25048828,  0.14477539, -0.10107422,  0.0012207 ,\n",
       "         -0.13549805, -0.19714355, -0.20068359,  0.06835938, -0.12036133,\n",
       "          0.13391113, -0.40722656,  0.03369141, -0.05749512,  0.22265625,\n",
       "          0.296875  , -0.19970703, -0.06970215, -0.3203125 ,  0.04418945,\n",
       "          0.027771  ,  0.25097656, -0.01123047,  0.26635742, -0.11865234,\n",
       "         -0.10317993,  0.0925293 ,  0.20361328,  0.12866211,  0.24951172,\n",
       "          0.03173828,  0.06500244, -0.14111328,  0.20703125, -0.30761719,\n",
       "         -0.13037109, -0.02001953,  0.25219727, -0.00256348,  0.02734375,\n",
       "         -0.02154541,  0.13916016, -0.15563965,  0.08959961, -0.01699829,\n",
       "         -0.19433594,  0.21240234,  0.02282715,  0.24658203, -0.00878906,\n",
       "          0.12121582, -0.03149414, -0.12304688, -0.12451172,  0.05932617,\n",
       "         -0.17407227,  0.05859375,  0.09643555, -0.19287109, -0.18212891,\n",
       "         -0.10906982, -0.21484375,  0.19628906, -0.06750488,  0.01208496,\n",
       "          0.0604248 , -0.23242188,  0.00699615, -0.02496338, -0.00097656,\n",
       "         -0.19189453, -0.07324219,  0.07617188, -0.04418945,  0.1015625 ,\n",
       "          0.10424805, -0.07495117, -0.02563477, -0.14819336,  0.09277344,\n",
       "         -0.09197998,  0.21630859, -0.26806641,  0.09594727, -0.09448242,\n",
       "         -0.08862305, -0.10046387,  0.05801773,  0.13366699,  0.05957031,\n",
       "          0.14013672, -0.04858398, -0.34765625, -0.02923584, -0.07159424,\n",
       "          0.04248047,  0.11948395,  0.12744141, -0.09362793, -0.08306885,\n",
       "          0.19091797,  0.21134949, -0.09475708, -0.08538818,  0.05474854,\n",
       "         -0.14416504, -0.19140625, -0.18261719, -0.18505859, -0.03381348,\n",
       "         -0.1262207 ,  0.13818359, -0.10308838,  0.12207031,  0.10894775,\n",
       "          0.20855713,  0.15234375,  0.17529297,  0.32568359, -0.04437256,\n",
       "          0.15649414,  0.04205322, -0.10388184, -0.03466797, -0.29101562,\n",
       "          0.13964844, -0.01544189,  0.01669312, -0.13513184, -0.18701172,\n",
       "         -0.0859375 ,  0.18701172, -0.08337402,  0.12078857,  0.08447266,\n",
       "          0.03855896,  0.07629395, -0.07250977,  0.24121094, -0.03930664,\n",
       "          0.33398438,  0.27880859,  0.18652344,  0.08813477,  0.00439453,\n",
       "          0.26269531, -0.26904297,  0.12866211,  0.06573486, -0.00708008,\n",
       "         -0.11645508,  0.13018799, -0.02947998, -0.04696655,  0.14038086,\n",
       "          0.00634766, -0.08618164, -0.15869141, -0.03216553, -0.16296387,\n",
       "          0.0390625 ,  0.03076172, -0.06809998,  0.06054688, -0.14746094,\n",
       "          0.01489258,  0.05667114,  0.09741211, -0.12963867,  0.03820801,\n",
       "         -0.07275391, -0.01025391, -0.29589844, -0.01647949,  0.00463867,\n",
       "          0.0078125 ,  0.05645752,  0.04541016,  0.07885742,  0.12011719,\n",
       "         -0.00195312,  0.22680664,  0.01391602, -0.08996582, -0.18488312,\n",
       "         -0.00244141,  0.10742188,  0.12670898,  0.23193359, -0.00488281,\n",
       "          0.1953125 ,  0.0489502 , -0.0234375 , -0.1184082 , -0.03198242,\n",
       "          0.15209961,  0.16357422, -0.05541992, -0.13246155,  0.03491211,\n",
       "         -0.35595703, -0.06964111, -0.12374878, -0.04272461, -0.01611328,\n",
       "         -0.05822754, -0.05004883,  0.17613602, -0.40332031,  0.11108398,\n",
       "          0.07388306, -0.34863281,  0.03710938, -0.12744141,  0.19873047,\n",
       "         -0.08032227, -0.11914062, -0.03448486, -0.01123047,  0.19482422,\n",
       "          0.09423828,  0.10217285, -0.11743164,  0.36621094, -0.01904297]),\n",
       "  array([ 4.52473958e-02, -1.61621094e-01, -1.50227865e-01, -4.93164062e-02,\n",
       "          1.59505208e-02,  1.33300781e-01, -1.10677083e-02, -1.27766927e-01,\n",
       "          1.09619141e-01,  5.72916667e-02, -8.62630208e-03,  2.39257812e-02,\n",
       "         -1.36230469e-01, -3.04260254e-02,  4.16666667e-02,  4.47591146e-02,\n",
       "          1.25203451e-01,  1.70572917e-01,  4.36808268e-02, -9.44010417e-02,\n",
       "          9.96093750e-02,  1.22070312e-01,  1.45345052e-01,  4.28670247e-02,\n",
       "          1.47094727e-02,  4.64274089e-02, -5.52571615e-02,  1.87011719e-01,\n",
       "          5.23274740e-02, -1.31510417e-01,  2.67130534e-02, -5.66406250e-02,\n",
       "         -8.54492188e-02, -5.53385417e-03,  4.16666667e-02, -1.62272135e-01,\n",
       "         -1.19140625e-01, -1.28255208e-01,  2.64973958e-01, -4.48404948e-02,\n",
       "         -4.72005208e-02,  1.24348958e-01,  1.20442708e-02,  9.99348958e-02,\n",
       "         -1.46158854e-01, -1.78385417e-01, -4.61832682e-03,  4.94791667e-02,\n",
       "         -7.89388021e-02,  1.74153646e-01,  2.83813477e-02,  1.36515299e-01,\n",
       "         -3.45865885e-02,  1.45014445e-01, -3.48002116e-02,  1.20686849e-01,\n",
       "          7.16145833e-02,  2.58789062e-02,  6.86848958e-02,  4.80143229e-02,\n",
       "         -1.33443197e-01, -8.69140625e-02, -2.11751302e-01,  1.37532552e-01,\n",
       "         -1.31693522e-01, -7.76570638e-02, -1.62923177e-01,  1.08520508e-01,\n",
       "          1.64713542e-01,  1.53645833e-01, -1.55578613e-01,  6.52465820e-02,\n",
       "          2.23958333e-01,  6.78710938e-02,  5.11474609e-02,  6.65690104e-02,\n",
       "         -5.32226562e-02,  9.73307292e-02,  7.64567057e-02, -6.64469401e-02,\n",
       "         -5.66558838e-02,  1.16780599e-02,  3.88997396e-02,  1.60481771e-01,\n",
       "         -1.22070312e-02, -1.41113281e-01, -7.49308268e-02,  9.97721354e-02,\n",
       "         -5.83699544e-02,  1.30208333e-01,  1.93359375e-01, -3.00130208e-01,\n",
       "         -1.55598958e-01, -1.77408854e-01,  7.38932292e-02, -1.66870117e-01,\n",
       "          1.18245443e-01,  1.18815104e-02,  8.66699219e-02,  1.83430990e-01,\n",
       "          2.21354167e-02, -1.03434245e-01, -5.19205729e-02,  8.52050781e-02,\n",
       "         -7.21842448e-02,  2.88085938e-02, -1.24267578e-01,  2.97444661e-02,\n",
       "          9.55403646e-02, -2.14192708e-01, -6.22660319e-02,  4.02018229e-02,\n",
       "         -1.25895182e-01, -1.26953125e-02,  2.22005208e-01, -3.74348958e-03,\n",
       "          2.44140625e-02, -4.54101562e-02,  2.68229167e-01,  1.28580729e-02,\n",
       "          1.77408854e-02,  3.14941406e-02, -1.21663411e-01,  8.90096029e-02,\n",
       "          1.05143229e-01, -3.34472656e-02, -2.13378906e-01,  2.53417969e-01,\n",
       "          5.37109375e-03,  5.75358073e-02, -6.60603841e-02,  1.40462240e-01,\n",
       "         -1.29231771e-01,  1.26953125e-01, -1.92382812e-01,  1.29882812e-01,\n",
       "          1.38509115e-01,  1.36393229e-01, -1.26302083e-01, -5.44026693e-02,\n",
       "          6.08723958e-02, -1.54785156e-01,  1.05794271e-02, -2.86458333e-02,\n",
       "          1.79036458e-03, -1.02416992e-01,  1.22604370e-01,  1.62760417e-04,\n",
       "         -1.80664062e-01, -1.42252604e-01,  1.84733073e-02,  2.01822917e-01,\n",
       "         -1.08317057e-01,  3.01106771e-02, -5.74544271e-02, -4.97233073e-02,\n",
       "          8.46354167e-03, -8.20312500e-02, -4.37011719e-02, -5.80037435e-02,\n",
       "         -2.24121094e-01,  3.16162109e-02, -3.00618490e-01,  1.07666016e-01,\n",
       "          1.29069010e-01,  4.34570312e-02, -1.95312500e-02, -2.22330729e-01,\n",
       "         -8.64257812e-02, -6.83746338e-02,  6.68945312e-02,  1.57877604e-02,\n",
       "          8.28857422e-02, -1.46809896e-01,  3.82080078e-02,  2.27864583e-02,\n",
       "          6.36800130e-02, -1.04492188e-01,  1.98974609e-02,  6.47379557e-02,\n",
       "          1.12630208e-01, -9.84293620e-02, -5.81054688e-02, -1.09700521e-01,\n",
       "          2.21008301e-01, -1.99544271e-01, -1.01989746e-01, -7.02311198e-02,\n",
       "          1.78873698e-01,  1.56250000e-02, -1.19384766e-01,  1.80664062e-02,\n",
       "         -1.46769206e-01,  1.09863281e-01, -1.26953125e-02,  7.10449219e-02,\n",
       "          3.78417969e-02, -1.17838542e-01,  1.38346354e-01, -3.39518229e-01,\n",
       "         -6.89697266e-02,  2.73437500e-02,  1.44531250e-01, -2.40885417e-02,\n",
       "         -6.90714518e-02, -6.20524089e-02,  1.41764323e-01, -1.97591146e-01,\n",
       "         -8.62833659e-02,  9.14204915e-02, -4.49015299e-02,  1.62760417e-04,\n",
       "         -9.79817708e-02, -1.73502604e-01,  1.82617188e-01,  1.13769531e-01,\n",
       "          3.32845052e-02,  9.76765951e-02, -2.11914062e-01, -1.67541504e-02,\n",
       "         -9.74121094e-02, -3.41796875e-02,  1.63330078e-01, -2.52278646e-02,\n",
       "         -8.51236979e-02, -1.15356445e-01,  5.55013021e-02, -2.07519531e-01,\n",
       "          2.08333333e-02, -1.89778646e-01, -1.10829671e-01, -1.67805990e-01,\n",
       "         -1.20768229e-01, -1.71549479e-01,  7.19401042e-02, -8.45947266e-02,\n",
       "          7.79622396e-02,  1.31479899e-02, -2.01009115e-02,  1.46809896e-01,\n",
       "          2.23673503e-01, -1.91650391e-02, -6.16861979e-02, -1.17187500e-01,\n",
       "          1.93196615e-01, -1.05010986e-01, -1.51285807e-01,  1.94010417e-01,\n",
       "         -1.23046875e-01, -1.37532552e-01, -3.98356120e-02,  5.71289062e-02,\n",
       "         -7.42187500e-02,  1.73258464e-01,  2.04752604e-01, -4.23177083e-02,\n",
       "         -5.17578125e-02, -1.42517090e-02, -1.42415365e-01, -2.14925130e-01,\n",
       "         -1.46484375e-03, -7.93457031e-02,  1.13444010e-01,  1.24104818e-02,\n",
       "         -6.36393229e-02,  6.80338542e-02, -1.37705485e-01, -1.08561198e-01,\n",
       "         -3.16406250e-01, -1.60319010e-01, -9.78190104e-02,  1.09469096e-02,\n",
       "         -2.27050781e-02, -1.37858073e-01,  9.19596354e-02, -2.89510091e-02,\n",
       "         -1.13301595e-01,  1.22904460e-01,  1.53422038e-01, -3.89811198e-02,\n",
       "         -1.32486979e-01, -7.33642578e-02,  1.37776693e-01, -1.78222656e-02,\n",
       "         -3.04361979e-02,  1.11328125e-01, -5.02929688e-02,  1.77083333e-01,\n",
       "          2.07031250e-01,  9.48079427e-03,  7.38932292e-02,  3.74348958e-03,\n",
       "         -1.90755208e-01,  9.54182943e-02, -2.76692708e-03, -2.47070312e-01,\n",
       "          3.24869792e-01, -3.12500000e-02, -4.31315104e-02,  4.06901042e-02]),\n",
       "  array([ 0.00966506,  0.02071242, -0.06020321,  0.08475798, -0.07089095,\n",
       "          0.02283426,  0.04436952, -0.08662831,  0.05500308,  0.04784827,\n",
       "         -0.0060241 , -0.03792919, -0.04111828,  0.00276947, -0.06277466,\n",
       "          0.09554291,  0.01153981,  0.07926247,  0.04626673, -0.03762297,\n",
       "         -0.0236747 , -0.01766448, -0.02223067,  0.05105521,  0.01314423,\n",
       "         -0.01219039, -0.03568961,  0.05138501, -0.00037375, -0.02546692,\n",
       "         -0.01497581, -0.06330455, -0.02179233, -0.04436285,  0.01368089,\n",
       "         -0.00381054,  0.00461544,  0.01527682,  0.03235557,  0.04951503,\n",
       "          0.05150257, -0.01785148,  0.08365007,  0.00351195, -0.08774983,\n",
       "         -0.16477411, -0.0393108 ,  0.02444215, -0.04570285,  0.0342976 ,\n",
       "          0.0257017 , -0.00418264, -0.00260232,  0.00999589,  0.007131  ,\n",
       "         -0.02590249, -0.0463562 , -0.02966447,  0.03533658, -0.07725715,\n",
       "         -0.04821392,  0.03024673, -0.13932315, -0.02830783, -0.0101627 ,\n",
       "         -0.01394237, -0.03597398,  0.03565216,  0.0029876 ,  0.05998785,\n",
       "         -0.02263364, -0.05269571,  0.10526276,  0.01238736, -0.0253823 ,\n",
       "         -0.12145511,  0.06071958,  0.12151129, -0.00537079,  0.05242365,\n",
       "         -0.01749169, -0.04297569,  0.00622559,  0.07786456,  0.00115273,\n",
       "         -0.04989468, -0.08045821,  0.06472536,  0.0329616 ,  0.02828494,\n",
       "          0.11688926, -0.01483154, -0.0728266 , -0.15098156,  0.01140803,\n",
       "         -0.08257294,  0.02369413,  0.00894373,  0.04178637, -0.02891922,\n",
       "         -0.05396409, -0.05292511, -0.01861087,  0.05650884,  0.00327444,\n",
       "         -0.12638716, -0.01213004, -0.02112926,  0.08590941, -0.06879425,\n",
       "          0.00123388, -0.02338409, -0.03570106,  0.0110165 ,  0.07449618,\n",
       "          0.03485801,  0.02387238, -0.06920554,  0.09068992,  0.05169678,\n",
       "         -0.00904205,  0.00402223, -0.03657948,  0.10415511, -0.00899558,\n",
       "          0.03117336, -0.04779191, -0.03317989,  0.02072421,  0.035021  ,\n",
       "         -0.0446271 , -0.08828458, -0.05204946, -0.07129513, -0.02459925,\n",
       "         -0.04096707, -0.00259261,  0.06651451, -0.01797572,  0.0828808 ,\n",
       "          0.03633673, -0.07102689, -0.00462099,  0.00996121, -0.00700933,\n",
       "         -0.04300759,  0.01829529, -0.07506141, -0.02938496, -0.02845955,\n",
       "          0.07991721,  0.04677356, -0.0672897 ,  0.02282437,  0.01111637,\n",
       "         -0.03909128, -0.02821153, -0.06450748, -0.04710735, -0.08525606,\n",
       "          0.00541514,  0.05068484, -0.04345114,  0.0430629 ,  0.00971707,\n",
       "         -0.05638192,  0.01575331, -0.07853785,  0.01211756, -0.04699222,\n",
       "         -0.0749373 , -0.08215332, -0.01019565, -0.10411627,  0.01684882,\n",
       "         -0.03371984,  0.09940269, -0.07032481, -0.03033551,  0.02861162,\n",
       "         -0.11324692, -0.08540561,  0.04270692,  0.02183723, -0.04896545,\n",
       "         -0.0386822 , -0.01172465,  0.03546489,  0.0587505 ,  0.02739091,\n",
       "          0.01713493, -0.02242045, -0.01106123, -0.02670982, -0.0903061 ,\n",
       "          0.00757564,  0.01032118,  0.01893685, -0.07664074, -0.12695798,\n",
       "         -0.05942908,  0.09846913,  0.00120544, -0.04073576, -0.01092945,\n",
       "         -0.05895025, -0.08537327, -0.00291582,  0.00062318,  0.00082051,\n",
       "          0.01438349,  0.06867842, -0.041094  ,  0.13008473, -0.03580752,\n",
       "          0.06839822,  0.11042369,  0.05419107, -0.07896766,  0.00283952,\n",
       "         -0.0025829 ,  0.0200126 , -0.00957576, -0.00219228,  0.0127619 ,\n",
       "         -0.03300823,  0.03783928, -0.04469403,  0.04735218, -0.00667988,\n",
       "         -0.00801468, -0.02491361,  0.048172  ,  0.00572351,  0.03427401,\n",
       "         -0.00954333,  0.02185613, -0.05022881,  0.03986983,  0.00082069,\n",
       "          0.02585949,  0.00305731,  0.03058694, -0.08566007, -0.00221946,\n",
       "          0.00807745, -0.00839892,  0.04137221,  0.00061885, -0.09145355,\n",
       "         -0.01439493,  0.05574937,  0.00201832,  0.04633695,  0.04316711,\n",
       "          0.00692055,  0.01385221,  0.0043009 , -0.05797213,  0.00820923,\n",
       "          0.03135681, -0.03651706,  0.00258775,  0.08321207, -0.00290038,\n",
       "          0.09080644, -0.00734641,  0.01722769, -0.08508464, -0.07056358,\n",
       "          0.00500939,  0.09692799,  0.05609443,  0.04597785,  0.06993935,\n",
       "         -0.02641504, -0.09212702, -0.08234787, -0.07004894,  0.01170557,\n",
       "         -0.02726052,  0.00018588,  0.03170672,  0.08605263,  0.00221356,\n",
       "          0.00820923, -0.05125982,  0.05266363,  0.0813023 ,  0.01726861,\n",
       "         -0.08508301,  0.08215263, -0.09984103, -0.05848139, -0.03039898,\n",
       "          0.01994029,  0.0416473 , -0.04765875,  0.05230834, -0.04176788])])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(x_train[0]), len(x_train[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(827, (9, 300))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train),np.array(x_train[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((827, 9, 300), (827, 31), numpy.float64, numpy.ndarray, (827, 31))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "# l_trainn = to_categorical(l_train,31)\n",
    "# l_testt = to_categorical(l_test,31)\n",
    "x_train.shape, y_train.shape, type(y_train[0][0]), type(l_trainn),l_trainn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Exploratoty Data Analysis\n",
    "\n",
    "_Include EDA steps like finding distribution of Departments in this part, you may also use plots for EDA._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Modelling & Evaluation\n",
    "\n",
    "_Include all model prepration & evaluation steps in this part._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(gt,preds):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for t in gt:\n",
    "        if t in preds:\n",
    "            TP+=1\n",
    "        else:\n",
    "            FN+=1\n",
    "    for p in preds:\n",
    "        if p not in gt:\n",
    "            FP+=1\n",
    "    if TP+FP==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/float(TP+FP)\n",
    "    if TP+FN==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/float(TP+FN)\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((827, 9, 300), (827, 31), numpy.float64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, type(y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 300),\n",
       " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape, y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 9, 300)\n",
      "('x_train shape ', (827, 2700))\n",
      "('x_test shape ', (335, 2700))\n",
      "('y_train shape ', (827, 31))\n",
      "('y_test shape ', (335, 31))\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_r = x_train.reshape(827,2700)\n",
    "xt_r = x_test.reshape(335,2700)\n",
    "for i in range(len(x_r)):\n",
    "    if np.isnan(x_r[i].all()):\n",
    "        print(true)\n",
    "        break\n",
    "\n",
    "print(\"x_train shape \", x_r.shape)\n",
    "print(\"x_test shape \", xt_r.shape)\n",
    "print(\"y_train shape \", y_train.shape)\n",
    "print(\"y_test shape \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1240, kernel_regularizer=<keras.reg..., input_shape=(2700,))`\n",
      "  import sys\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(124, kernel_regularizer=<keras.reg...)`\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(31, kernel_regularizer=<keras.reg...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1240, input_shape=(2700,),  W_regularizer=l2(0.01)),\n",
    "    Activation('relu'),\n",
    "    Dense(124, W_regularizer=l2(0.01)),\n",
    "    Activation('relu'),\n",
    "    Dense(31, W_regularizer=l2(0.01)),\n",
    "    Activation('softmax')\n",
    "])\n",
    "#opt = optimizers.sgd(lr=0.0001, decay=1e-6)\n",
    "opt = optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.4, nesterov=False)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "827/827 [==============================] - 2s - loss: 22.1409 - acc: 0.4498     \n",
      "Epoch 2/100\n",
      "827/827 [==============================] - 1s - loss: 20.0111 - acc: 0.6094     \n",
      "Epoch 3/100\n",
      "827/827 [==============================] - 1s - loss: 18.3439 - acc: 0.6409     \n",
      "Epoch 4/100\n",
      "827/827 [==============================] - 1s - loss: 16.9055 - acc: 0.6409     \n",
      "Epoch 5/100\n",
      "827/827 [==============================] - 1s - loss: 15.6178 - acc: 0.6481     \n",
      "Epoch 6/100\n",
      "827/827 [==============================] - 1s - loss: 14.4506 - acc: 0.7231     \n",
      "Epoch 7/100\n",
      "827/827 [==============================] - 1s - loss: 13.3792 - acc: 0.7775     \n",
      "Epoch 8/100\n",
      "827/827 [==============================] - 1s - loss: 12.4002 - acc: 0.8222     \n",
      "Epoch 9/100\n",
      "827/827 [==============================] - 1s - loss: 11.4987 - acc: 0.8404     \n",
      "Epoch 10/100\n",
      "827/827 [==============================] - 1s - loss: 10.6690 - acc: 0.8561     \n",
      "Epoch 11/100\n",
      "827/827 [==============================] - 1s - loss: 9.9099 - acc: 0.8634     \n",
      "Epoch 12/100\n",
      "827/827 [==============================] - 1s - loss: 9.2125 - acc: 0.8706     \n",
      "Epoch 13/100\n",
      "827/827 [==============================] - 1s - loss: 8.5692 - acc: 0.8791     \n",
      "Epoch 14/100\n",
      "827/827 [==============================] - 1s - loss: 7.9757 - acc: 0.8815     \n",
      "Epoch 15/100\n",
      "827/827 [==============================] - 1s - loss: 7.4343 - acc: 0.8888     \n",
      "Epoch 16/100\n",
      "827/827 [==============================] - 1s - loss: 6.9358 - acc: 0.8851     \n",
      "Epoch 17/100\n",
      "827/827 [==============================] - 1s - loss: 6.4760 - acc: 0.8924     \n",
      "Epoch 18/100\n",
      "827/827 [==============================] - 1s - loss: 6.0541 - acc: 0.8948     \n",
      "Epoch 19/100\n",
      "827/827 [==============================] - 1s - loss: 5.6688 - acc: 0.9008     \n",
      "Epoch 20/100\n",
      "827/827 [==============================] - 1s - loss: 5.3139 - acc: 0.9093     \n",
      "Epoch 21/100\n",
      "827/827 [==============================] - 1s - loss: 4.9889 - acc: 0.9081     \n",
      "Epoch 22/100\n",
      "827/827 [==============================] - 1s - loss: 4.6923 - acc: 0.9021     \n",
      "Epoch 23/100\n",
      "827/827 [==============================] - 1s - loss: 4.4172 - acc: 0.9154     \n",
      "Epoch 24/100\n",
      "827/827 [==============================] - 1s - loss: 4.1643 - acc: 0.9166     \n",
      "Epoch 25/100\n",
      "827/827 [==============================] - 1s - loss: 3.9364 - acc: 0.9141     \n",
      "Epoch 26/100\n",
      "827/827 [==============================] - 0s - loss: 3.7260 - acc: 0.9154     \n",
      "Epoch 27/100\n",
      "827/827 [==============================] - 1s - loss: 3.5347 - acc: 0.9190     \n",
      "Epoch 28/100\n",
      "827/827 [==============================] - 1s - loss: 3.3578 - acc: 0.9214     \n",
      "Epoch 29/100\n",
      "827/827 [==============================] - 1s - loss: 3.1990 - acc: 0.9190     \n",
      "Epoch 30/100\n",
      "827/827 [==============================] - 0s - loss: 3.0531 - acc: 0.9250     \n",
      "Epoch 31/100\n",
      "827/827 [==============================] - 0s - loss: 2.9145 - acc: 0.9166     \n",
      "Epoch 32/100\n",
      "827/827 [==============================] - 1s - loss: 2.7909 - acc: 0.9250     \n",
      "Epoch 33/100\n",
      "827/827 [==============================] - 0s - loss: 2.6759 - acc: 0.9262     \n",
      "Epoch 34/100\n",
      "827/827 [==============================] - 1s - loss: 2.5748 - acc: 0.9262     \n",
      "Epoch 35/100\n",
      "827/827 [==============================] - 1s - loss: 2.4817 - acc: 0.9214     \n",
      "Epoch 36/100\n",
      "827/827 [==============================] - 1s - loss: 2.3956 - acc: 0.9250     \n",
      "Epoch 37/100\n",
      "827/827 [==============================] - 1s - loss: 2.3141 - acc: 0.9190     \n",
      "Epoch 38/100\n",
      "827/827 [==============================] - 1s - loss: 2.2413 - acc: 0.9262     \n",
      "Epoch 39/100\n",
      "827/827 [==============================] - 1s - loss: 2.1748 - acc: 0.9226     \n",
      "Epoch 40/100\n",
      "827/827 [==============================] - 1s - loss: 2.1101 - acc: 0.9299     \n",
      "Epoch 41/100\n",
      "827/827 [==============================] - 0s - loss: 2.0540 - acc: 0.9274     \n",
      "Epoch 42/100\n",
      "827/827 [==============================] - 1s - loss: 2.0046 - acc: 0.9262     \n",
      "Epoch 43/100\n",
      "827/827 [==============================] - 1s - loss: 1.9538 - acc: 0.9238     \n",
      "Epoch 44/100\n",
      "827/827 [==============================] - 1s - loss: 1.9098 - acc: 0.9274     \n",
      "Epoch 45/100\n",
      "827/827 [==============================] - 1s - loss: 1.8677 - acc: 0.9250     \n",
      "Epoch 46/100\n",
      "827/827 [==============================] - 1s - loss: 1.8288 - acc: 0.9299     \n",
      "Epoch 47/100\n",
      "827/827 [==============================] - 1s - loss: 1.7945 - acc: 0.9274     \n",
      "Epoch 48/100\n",
      "827/827 [==============================] - 1s - loss: 1.7598 - acc: 0.9287     \n",
      "Epoch 49/100\n",
      "827/827 [==============================] - 1s - loss: 1.7301 - acc: 0.9287     \n",
      "Epoch 50/100\n",
      "827/827 [==============================] - 1s - loss: 1.7017 - acc: 0.9311     \n",
      "Epoch 51/100\n",
      "827/827 [==============================] - 1s - loss: 1.6757 - acc: 0.9274     \n",
      "Epoch 52/100\n",
      "827/827 [==============================] - 1s - loss: 1.6514 - acc: 0.9287     \n",
      "Epoch 53/100\n",
      "827/827 [==============================] - 1s - loss: 1.6268 - acc: 0.9274     \n",
      "Epoch 54/100\n",
      "827/827 [==============================] - 1s - loss: 1.6053 - acc: 0.9250     \n",
      "Epoch 55/100\n",
      "827/827 [==============================] - 1s - loss: 1.5849 - acc: 0.9299     \n",
      "Epoch 56/100\n",
      "827/827 [==============================] - 1s - loss: 1.5636 - acc: 0.9299     \n",
      "Epoch 57/100\n",
      "827/827 [==============================] - 1s - loss: 1.5481 - acc: 0.9287     \n",
      "Epoch 58/100\n",
      "827/827 [==============================] - 1s - loss: 1.5318 - acc: 0.9287     \n",
      "Epoch 59/100\n",
      "827/827 [==============================] - 1s - loss: 1.5151 - acc: 0.9287     \n",
      "Epoch 60/100\n",
      "827/827 [==============================] - 1s - loss: 1.4979 - acc: 0.9323     \n",
      "Epoch 61/100\n",
      "827/827 [==============================] - 1s - loss: 1.4848 - acc: 0.9287     \n",
      "Epoch 62/100\n",
      "827/827 [==============================] - 1s - loss: 1.4729 - acc: 0.9250     \n",
      "Epoch 63/100\n",
      "827/827 [==============================] - 1s - loss: 1.4624 - acc: 0.9262     \n",
      "Epoch 64/100\n",
      "827/827 [==============================] - 1s - loss: 1.4465 - acc: 0.9287     \n",
      "Epoch 65/100\n",
      "827/827 [==============================] - 1s - loss: 1.4348 - acc: 0.9274     \n",
      "Epoch 66/100\n",
      "827/827 [==============================] - 1s - loss: 1.4260 - acc: 0.9274     \n",
      "Epoch 67/100\n",
      "827/827 [==============================] - 1s - loss: 1.4163 - acc: 0.9238     \n",
      "Epoch 68/100\n",
      "827/827 [==============================] - 1s - loss: 1.4055 - acc: 0.9274     \n",
      "Epoch 69/100\n",
      "827/827 [==============================] - 1s - loss: 1.3936 - acc: 0.9250     \n",
      "Epoch 70/100\n",
      "827/827 [==============================] - 1s - loss: 1.3833 - acc: 0.9250     \n",
      "Epoch 71/100\n",
      "827/827 [==============================] - 1s - loss: 1.3745 - acc: 0.9274     \n",
      "Epoch 72/100\n",
      "827/827 [==============================] - 1s - loss: 1.3661 - acc: 0.9262     \n",
      "Epoch 73/100\n",
      "827/827 [==============================] - 1s - loss: 1.3574 - acc: 0.9262     \n",
      "Epoch 74/100\n",
      "827/827 [==============================] - 1s - loss: 1.3511 - acc: 0.9250     \n",
      "Epoch 75/100\n",
      "827/827 [==============================] - 1s - loss: 1.3437 - acc: 0.9262     \n",
      "Epoch 76/100\n",
      "827/827 [==============================] - 1s - loss: 1.3394 - acc: 0.9226     \n",
      "Epoch 77/100\n",
      "827/827 [==============================] - 1s - loss: 1.3337 - acc: 0.9250     \n",
      "Epoch 78/100\n",
      "827/827 [==============================] - 1s - loss: 1.3235 - acc: 0.9226     \n",
      "Epoch 79/100\n",
      "827/827 [==============================] - 1s - loss: 1.3176 - acc: 0.9262     \n",
      "Epoch 80/100\n",
      "827/827 [==============================] - 1s - loss: 1.3112 - acc: 0.9262     \n",
      "Epoch 81/100\n",
      "827/827 [==============================] - 1s - loss: 1.3047 - acc: 0.9190     \n",
      "Epoch 82/100\n",
      "827/827 [==============================] - 1s - loss: 1.3022 - acc: 0.9214     \n",
      "Epoch 83/100\n",
      "827/827 [==============================] - 1s - loss: 1.2940 - acc: 0.9250     \n",
      "Epoch 84/100\n",
      "827/827 [==============================] - 1s - loss: 1.2875 - acc: 0.9262     \n",
      "Epoch 85/100\n",
      "827/827 [==============================] - 1s - loss: 1.2811 - acc: 0.9262     \n",
      "Epoch 86/100\n",
      "827/827 [==============================] - 1s - loss: 1.2754 - acc: 0.9250     \n",
      "Epoch 87/100\n",
      "827/827 [==============================] - 1s - loss: 1.2710 - acc: 0.9226     \n",
      "Epoch 88/100\n",
      "827/827 [==============================] - 1s - loss: 1.2674 - acc: 0.9226     \n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827/827 [==============================] - 1s - loss: 1.2614 - acc: 0.9250     \n",
      "Epoch 90/100\n",
      "827/827 [==============================] - 1s - loss: 1.2571 - acc: 0.9202     \n",
      "Epoch 91/100\n",
      "827/827 [==============================] - 1s - loss: 1.2568 - acc: 0.9226     \n",
      "Epoch 92/100\n",
      "827/827 [==============================] - 1s - loss: 1.2512 - acc: 0.9190     \n",
      "Epoch 93/100\n",
      "827/827 [==============================] - 1s - loss: 1.2489 - acc: 0.9154     \n",
      "Epoch 94/100\n",
      "827/827 [==============================] - 1s - loss: 1.2413 - acc: 0.9214     \n",
      "Epoch 95/100\n",
      "827/827 [==============================] - 1s - loss: 1.2398 - acc: 0.9238     \n",
      "Epoch 96/100\n",
      "827/827 [==============================] - 1s - loss: 1.2363 - acc: 0.9214     \n",
      "Epoch 97/100\n",
      "827/827 [==============================] - 1s - loss: 1.2301 - acc: 0.9214     \n",
      "Epoch 98/100\n",
      "827/827 [==============================] - 1s - loss: 1.2283 - acc: 0.9178     \n",
      "Epoch 99/100\n",
      "827/827 [==============================] - 1s - loss: 1.2245 - acc: 0.9214     \n",
      "Epoch 100/100\n",
      "827/827 [==============================] - 1s - loss: 1.2218 - acc: 0.9178     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8c44910>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_r, y_train, epochs=100, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=model.predict(xt_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/335 [===========================>..] - ETA: 0s('Model metrics: ', ['loss', 'acc'])\n",
      "('TEST ACCURACY: ', 0.9134328363546684)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(xt_r, y_test, batch_size=64)\n",
    "print(\"Model metrics: \",model.metrics_names)\n",
    "print(\"TEST ACCURACY: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.30382870489092, 0.9134328363546684]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Summary:**\n",
    "_Provide a brief summary of results obtained like model accuracy & other insights based on EDA & your interpretations_\n",
    "\n",
    "Key problems that I tackeled were:\n",
    "1. Data was very unorganized and random, understanding it, preprocessing it and organizing it took a bit of effort.\n",
    "2. Embeddings played an important role, how to use them to predict the class was something to be thought upon.\n",
    "3. Extacted important features from the data and removed the redundant features on my own.\n",
    "4. Major problem was the missing data and some words not being present in the vocabulary of word model. Missing data started to give me nan loss from the first iteration. For missing data, I aim to go throught this paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.6971 . As of now, I returned a very small sentence vector if data is missing.\n",
    "5. I was planing to use universal sentence encoder but that was too big for me to download at my home, as of now, I just used word2vec embeddings and averaged out the embeddings for a sentence.\n",
    "6. Instead of using random small vector, incorporate an unknown vector.\n",
    "7. Since emebddings are already normalized, I did not really normalized the training data.\n",
    "\n",
    "1. Got testing accuracy to be around 91.3 % which is on 335 samples and I used 827 samples in total to train the model.\n",
    "2. Loss is around 1.3 on test data. Used softmax in last layer.\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningproject",
   "language": "python",
   "name": "deeplearningproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
